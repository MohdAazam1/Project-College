{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dea955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\onedrive\\desktop\\project\\venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#installing kaggel library\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28561305",
   "metadata": {},
   "source": [
    "importing sentiment analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c8cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\LENOVO\\OneDrive\\Desktop\\Project\\venv\\Scripts\\kaggle.exe\\__main__.py\", line 6, in <module>\n",
      "  File \"C:\\Users\\LENOVO\\OneDrive\\Desktop\\Project\\venv\\Lib\\site-packages\\kaggle\\cli.py\", line 68, in main\n",
      "    out = args.func(**command_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LENOVO\\OneDrive\\Desktop\\Project\\venv\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
      "    with self.build_kaggle_client() as kaggle:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LENOVO\\OneDrive\\Desktop\\Project\\venv\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
      "    username=self.config_values['username'],\n",
      "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'username'\n"
     ]
    }
   ],
   "source": [
    "#API to fetch the dataset from kaggle\n",
    "!kaggle datasets download -d kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76161ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is extracted\n"
     ]
    }
   ],
   "source": [
    "#Extracting the compressed dataset\n",
    "from zipfile import ZipFile\n",
    "dataset = 'C:/Users/LENOVO/OneDrive/Desktop/Project/Code/dataset.zip'\n",
    "\n",
    "with ZipFile(dataset, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('The dataset is extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f95056",
   "metadata": {},
   "source": [
    "Install necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d4ffe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52955d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca66dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "#printing the stopwords in english\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # <--- ADD THIS LINE\n",
    "\n",
    "# Now you can use stopwords directly:\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a089957",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57294637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data from csv file to pands dataframe\n",
    "twitter_data = pd.read_csv(\n",
    "    r'C:/Users/LENOVO/OneDrive/Desktop/Project/Code/dataset/training.1600000.processed.noemoticon.csv',\n",
    "    encoding='ISO-8859-1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bdccdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of rows and columns\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "355d2c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the first 5 rows of dataframes\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2ea9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming the columns adn reading the dataset again\n",
    "column_names = ['target','id','date','flag','user','text']\n",
    "twitter_data = pd.read_csv(r'C:/Users/LENOVO/OneDrive/Desktop/Project/Code/dataset/training.1600000.processed.noemoticon.csv', names=column_names, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c89ed9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of rows adn columns\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a090b61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the first 5 rows of dataframes\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f345f8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countin the number of missing values in the dataset\n",
    "twitter_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23c7a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the distribution of target column\n",
    "twitter_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e1c3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the target '4' to '1'\n",
    "twitter_data.replace({'target':{4:1}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b62be37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the distribution of target column\n",
    "twitter_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6d044",
   "metadata": {},
   "source": [
    "0 --> negative\n",
    "1 --> positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37f153",
   "metadata": {},
   "source": [
    "**STEMMING**\n",
    "Stemming is the process of reducing a word ot its root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed694f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2916e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9590847",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9acaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twitter_data['stemmed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twitter_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44776a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the data and label\n",
    "X = twitter_data['stemmed_content'].values\n",
    "Y = twitter_data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce47ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00dfb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22754e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb183a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb272d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a22ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the textual data to numerical value\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf65034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db453932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc608a",
   "metadata": {},
   "source": [
    "**Training the machine learning model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0856b6",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bce0a",
   "metadata": {},
   "source": [
    "Model evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98550bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score on the training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbce86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score on the training data: ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2304a",
   "metadata": {},
   "source": [
    "Accuracy on training data is 79.87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad59a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc87f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score on the training data: ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4f03d",
   "metadata": {},
   "source": [
    "Model accuracy = 77.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160821ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'logistic_regression_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the savaed model\n",
    "loaded_model = pickle.load(open(r'F:\\Code\\python\\logistic_regression_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aaf010",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[200]\n",
    "print(Y_test[200])\n",
    "\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "    print('negative tweet')\n",
    "\n",
    "else:\n",
    "    print('positive tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67405d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[3]\n",
    "print(Y_test[3])\n",
    "\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "    print('negative tweet')\n",
    "\n",
    "else:\n",
    "    print('positive tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b780be",
   "metadata": {},
   "source": [
    "Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67feb513",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4f433",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score\n",
    "bnb_pred = bnb.predict(X_test)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(Y_test, bnb_pred))\n",
    "print(\"\\nBernoulliNB Classification Report:\\n\", classification_report(Y_test, bnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'Naive_bayes_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392f249",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe88860",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f18a56e",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d95631",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(Y_test, svm_pred))\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(Y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55135fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'SVM_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
